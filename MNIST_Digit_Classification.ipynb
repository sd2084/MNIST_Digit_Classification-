{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNT3ur/1qxiVVSvKZ5c0fjK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sd2084/MNIST_Digit_Classification-/blob/main/MNIST_Digit_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Step 1: Load the MNIST dataset\n",
        "# Load the MNIST dataset, which contains 28x28 grayscale images of handwritten digits and their corresponding labels (0 to 9).\n",
        "# The dataset is split into training and testing sets, which we will use for training and evaluating the model.\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Step 2: Preprocess the data\n",
        "# Normalize the pixel values of the images to the range [0, 1] to make training more efficient and effective.\n",
        "# The pixel values of the images are originally in the range [0, 255].\n",
        "x_train = x_train.astype('float32') / 255\n",
        "x_test = x_test.astype('float32') / 255\n",
        "\n",
        "# Flatten the images from 28x28 to a 1D array (784) for the input layer of the neural network.\n",
        "# This reshaping is required because the neural network takes a 1D array as input, not a 2D image.\n",
        "x_train = x_train.reshape((-1, 28*28))\n",
        "x_test = x_test.reshape((-1, 28*28))\n",
        "\n",
        "# Step 3: Implement a simple neural network for digit classification\n",
        "# Create a sequential model, which is a linear stack of layers.\n",
        "# Add a hidden layer with 128 neurons and ReLU activation function to learn complex patterns from the input data.\n",
        "# Add an output layer with 10 neurons (one for each digit from 0 to 9) and softmax activation function to get probabilities for each class.\n",
        "model = Sequential()\n",
        "model.add(Dense(128, activation='relu', input_shape=(28*28,)))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "# Step 4: Compile the model\n",
        "# Compile the model with the categorical cross-entropy loss function for multi-class classification.\n",
        "# Use the Adam optimizer for training the model, which adapts the learning rate during training.\n",
        "# The model's performance will be measured using accuracy as the evaluation metric.\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Step 5: One-hot encode the labels\n",
        "# Convert the integer labels (0 to 9) to one-hot encoded vectors for training and testing.\n",
        "# One-hot encoding represents each label as a binary vector with a 1 at the corresponding class index and 0 elsewhere.\n",
        "y_train = to_categorical(y_train, num_classes=10)\n",
        "y_test = to_categorical(y_test, num_classes=10)\n",
        "\n",
        "# Step 6: Split the dataset into training and testing sets and train the model\n",
        "# The training data will be split further into training and validation sets (90% training, 10% validation).\n",
        "# Train the model on the training data and validate it on the validation data for 10 epochs (iterations over the entire training dataset).\n",
        "batch_size = 128\n",
        "epochs = 10\n",
        "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)\n",
        "\n",
        "# Step 7: Evaluate the model on the test set\n",
        "# Evaluate the trained model's performance on the test set and print the test accuracy.\n",
        "loss, accuracy = model.evaluate(x_test, y_test)\n",
        "print(\"Test accuracy:\", accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S8PGzjqicfon",
        "outputId": "e93ff8d0-4bf2-41b8-dc46-bec4dd8d2544"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "422/422 [==============================] - 4s 8ms/step - loss: 0.3786 - accuracy: 0.8978 - val_loss: 0.1764 - val_accuracy: 0.9507\n",
            "Epoch 2/10\n",
            "422/422 [==============================] - 2s 5ms/step - loss: 0.1767 - accuracy: 0.9496 - val_loss: 0.1269 - val_accuracy: 0.9652\n",
            "Epoch 3/10\n",
            "422/422 [==============================] - 2s 5ms/step - loss: 0.1285 - accuracy: 0.9640 - val_loss: 0.1043 - val_accuracy: 0.9713\n",
            "Epoch 4/10\n",
            "422/422 [==============================] - 2s 5ms/step - loss: 0.0993 - accuracy: 0.9716 - val_loss: 0.0921 - val_accuracy: 0.9723\n",
            "Epoch 5/10\n",
            "422/422 [==============================] - 2s 5ms/step - loss: 0.0797 - accuracy: 0.9770 - val_loss: 0.0874 - val_accuracy: 0.9735\n",
            "Epoch 6/10\n",
            "422/422 [==============================] - 3s 8ms/step - loss: 0.0649 - accuracy: 0.9815 - val_loss: 0.0774 - val_accuracy: 0.9758\n",
            "Epoch 7/10\n",
            "422/422 [==============================] - 2s 5ms/step - loss: 0.0542 - accuracy: 0.9848 - val_loss: 0.0764 - val_accuracy: 0.9773\n",
            "Epoch 8/10\n",
            "422/422 [==============================] - 2s 5ms/step - loss: 0.0465 - accuracy: 0.9867 - val_loss: 0.0745 - val_accuracy: 0.9780\n",
            "Epoch 9/10\n",
            "422/422 [==============================] - 2s 5ms/step - loss: 0.0388 - accuracy: 0.9893 - val_loss: 0.0746 - val_accuracy: 0.9777\n",
            "Epoch 10/10\n",
            "422/422 [==============================] - 2s 5ms/step - loss: 0.0327 - accuracy: 0.9913 - val_loss: 0.0787 - val_accuracy: 0.9762\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0791 - accuracy: 0.9750\n",
            "Test accuracy: 0.9750000238418579\n"
          ]
        }
      ]
    }
  ]
}